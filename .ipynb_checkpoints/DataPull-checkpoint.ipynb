{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tessleggio/GoogleDrive/GeorgiaTech/2018-Fall/01-ISYE-6414/6414Project\n"
     ]
    }
   ],
   "source": [
    "#cd /home/user1/Scripts/Python27/repos/aqs/\n",
    "\n",
    "import os\n",
    "os.chdir(\"/Users/tessleggio/GoogleDrive/GeorgiaTech/2018-Fall/01-ISYE-6414/6414Project\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandasql as ps\n",
    "import glob\n",
    "from dateutil import parser\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlemaps_api_key = \"AIzaSyAUax4y4YVGTXTWGCtSMgnSDSO0yY8kAzw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.read_csv(\"data/States.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap(string):\n",
    "    if isinstance(string, str):\n",
    "        return string.upper().replace(\" COUNTY\", \"\").capitalize().strip()\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_replace(df, col, orig, repl):\n",
    "    \"\"\"Function to remove all instances of a string orig from the column col in dataframe df\"\"\"\n",
    "        \n",
    "    count = 0\n",
    "    for word in df[col]:\n",
    "        df[col][count] = word.replace(orig, repl)\n",
    "        count += 1\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_county(lat,  lon):\n",
    "    \"\"\"Obtaining county corresponding to a latitude and longitude\"\"\"\n",
    "    \n",
    "    #Obtaining geo.fcc url \n",
    "    url = get_url(lat, lon)\n",
    "    print(url)\n",
    "    \n",
    "    #Requesting data from geo.fcc\n",
    "    response = requests.get(url)\n",
    "    content = json.loads(response.content.decode(\"latin1\"))\n",
    "    \n",
    "    if content[\"results\"]:\n",
    "        #Getting county\n",
    "        county = content[\"results\"][0][\"county_name\"]\n",
    "        state = content[\"results\"][0][\"state_name\"]\n",
    "    \n",
    "        return county, state\n",
    "    else:\n",
    "        return \"\", \"\"\n",
    "    \n",
    "def get_url(lat, lon):\n",
    "    request_url = \"https://geo.fcc.gov/api/census/area?lat=\" + str(lat) + \"&lon=\" + str(lon) + \"&format=json\"\n",
    "    return request_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maps_json(name):\n",
    "    response = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?address=\" + name.replace(\" \", \"+\") + \"&key=\" + googlemaps_api_key)\n",
    "    return json.loads(response.content.decode(\"latin1\"))\n",
    "\n",
    "def get_loc_from_name(name):\n",
    "    \n",
    "    #Getting json from google maps API:\n",
    "    response = get_maps_json(name)\n",
    "    \n",
    "    #Getting geographic component from response\n",
    "    if response[\"results\"]:\n",
    "        location = response[\"results\"][0][\"geometry\"][\"location\"]\n",
    "        return location[\"lat\"], location[\"lng\"]\n",
    "    else:\n",
    "        #If response is empty, return null values\n",
    "        return np.nan, np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd /home/user1/Scripts/Python27/repos/aqs/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#--------------------GETTING DATA--------------------\\n#----------------------------------------------------\\n\\n#Getting Per Capita Income Data by County (2014 - 2016)\\n!wget https://www.bea.gov/system/files/2017-12/lapi1117.xlsx\\n    \\n#Getting Population Data by County\\n!wget https://www2.census.gov/programs-surveys/popest/datasets/2010-2017/counties/totals/co-est2017-alldata.csv\\n\\n#Getting Power Plant data:\\n!for y in `seq 2012 2016`; do wget https://www.eia.gov/electricity/data/eia923/archive/xls/f923_${y}.zip; unzip f923_${y}.zip; rm f923_${y}.zip; done \\n!wget https://www.eia.gov/electricity/data/eia923/xls/f923_2017.zip; unzip f923_2017.zip; rm f923_2017.zip\\n!wget https://www.eia.gov/electricity/data/eia923/xls/f923_2018.zip; unzip f923_2018.zip; rm f923_2018.zip\\n\\n#Getting Daily AQI data for years 2014 - 2018:\\n! for i in `seq 2014 2018`; do wget https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_${i}.zip; unzip daily_aqi_by_county_${i}.zip; done \\n\\n#Getting Daily Temperature Data:\\n! for i in `seq 2014 2018`; do wget https://aqs.epa.gov/aqsweb/airdata/daily_TEMP_${i}.zip; unzip daily_TEMP_${i}.zip; done \\n    \\n#Getting Daily Wind Data:\\n! for i in `seq 2014 2018`; do wget https://aqs.epa.gov/aqsweb/airdata/daily_WIND_${i}.zip; unzip daily_WIND_${i}.zip; done \\n    \\n#Getting Daily Pressure Data:\\n! for i in `seq 2014 2018`; do wget https://aqs.epa.gov/aqsweb/airdata/daily_PRESS_${i}.zip; unzip daily_PRESS_${i}.zip; done \\n\\n#Getting Daily RH DH Data:\\n! for i in `seq 2014 2018`; do wget https://aqs.epa.gov/aqsweb/airdata/daily_RH_DP_${i}.zip; unzip daily_RH_DP_${i}.zip; done \\n\\n#Getting comprehensive 2016 FIPS geocoding data:\\n!wget https://www2.census.gov/programs-surveys/popest/geographies/2016/all-geocodes-v2016.xlsx\\n\\n#Getting powerplant location data\\n!wget https://www.eia.gov/electricity/data/eia860m/xls/august_generator2018.xlsx\\n\\n#Getting greeh-house gas emissions data\\n! for y in `seq 2010 2016`; do wget https://www.epa.gov/sites/production/files/2018-10/ghgp_data_${y}_8_19_2018.xlsx; done \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#--------------------GETTING DATA--------------------\n",
    "#----------------------------------------------------\n",
    "\n",
    "#Getting Per Capita Income Data by County (2014 - 2016)\n",
    "!wget https://www.bea.gov/system/files/2017-12/lapi1117.xlsx\n",
    "    \n",
    "#Getting Population Data by County\n",
    "!wget https://www2.census.gov/programs-surveys/popest/datasets/2010-2017/counties/totals/co-est2017-alldata.csv\n",
    "\n",
    "#Getting Power Plant data:\n",
    "!for y in `seq 2012 2016`; do wget https://www.eia.gov/electricity/data/eia923/archive/xls/f923_${y}.zip; unzip f923_${y}.zip; rm f923_${y}.zip; done \n",
    "!wget https://www.eia.gov/electricity/data/eia923/xls/f923_2017.zip; unzip f923_2017.zip; rm f923_2017.zip\n",
    "!wget https://www.eia.gov/electricity/data/eia923/xls/f923_2018.zip; unzip f923_2018.zip; rm f923_2018.zip\n",
    "\n",
    "#Getting Daily AQI data for years 2014 - 2018:\n",
    "! for i in `seq 2014 2018`; do wget https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_${i}.zip; unzip daily_aqi_by_county_${i}.zip; done \n",
    "\n",
    "#Getting Daily Temperature Data:\n",
    "! for i in `seq 2014 2018`; do wget https://aqs.epa.gov/aqsweb/airdata/daily_TEMP_${i}.zip; unzip daily_TEMP_${i}.zip; done \n",
    "    \n",
    "#Getting Daily Wind Data:\n",
    "! for i in `seq 2014 2018`; do wget https://aqs.epa.gov/aqsweb/airdata/daily_WIND_${i}.zip; unzip daily_WIND_${i}.zip; done \n",
    "    \n",
    "#Getting Daily Pressure Data:\n",
    "! for i in `seq 2014 2018`; do wget https://aqs.epa.gov/aqsweb/airdata/daily_PRESS_${i}.zip; unzip daily_PRESS_${i}.zip; done \n",
    "\n",
    "#Getting Daily RH DH Data:\n",
    "! for i in `seq 2014 2018`; do wget https://aqs.epa.gov/aqsweb/airdata/daily_RH_DP_${i}.zip; unzip daily_RH_DP_${i}.zip; done \n",
    "\n",
    "#Getting comprehensive 2016 FIPS geocoding data:\n",
    "!wget https://www2.census.gov/programs-surveys/popest/geographies/2016/all-geocodes-v2016.xlsx\n",
    "\n",
    "#Getting powerplant location data\n",
    "!wget https://www.eia.gov/electricity/data/eia860m/xls/august_generator2018.xlsx\n",
    "\n",
    "#Getting greeh-house gas emissions data\n",
    "! for y in `seq 2010 2016`; do wget https://www.epa.gov/sites/production/files/2018-10/ghgp_data_${y}_8_19_2018.xlsx; done \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>NumCensusAreas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alaska</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arizona</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arkansas</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>california</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  NumCensusAreas\n",
       "0     alabama              67\n",
       "1      alaska              29\n",
       "2     arizona              15\n",
       "3    arkansas              75\n",
       "4  california              58"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumCensusAreas = pd.read_csv(\"StatesNumCensusAreas.csv\", header=0)\n",
    "NumCensusAreas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily AQIs and Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------READING AND PRE-PROCESSING DAILY AQS AND WEATHER DATA-------------------\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "data = pd.read_csv(\"data/daily_aqi_by_county_2014.csv\")\n",
    "\n",
    "for i in range(2015, 2019):\n",
    "    data = pd.concat([data, pd.read_csv(\"data/daily_aqi_by_county_\" + str(i) + \".zip\")])    \n",
    "\n",
    "#_______________________________________________________\n",
    "#Loading in daily Air Pressure data for years 2014 - 2018\n",
    "\n",
    "data_ap = pd.read_csv(\"data/daily_PRESS_2014.csv\")\n",
    "\n",
    "for i in range(2015, 2019):\n",
    "    data_ap = pd.concat([data_ap, pd.read_csv(\"data/daily_PRESS_\" + str(i) + \".zip\")])\n",
    "    \n",
    "data_ap = data_ap[[\"State Code\", \"County Code\", \"Date Local\", \"Arithmetic Mean\"]]\n",
    "data_ap.rename(columns={\"Arithmetic Mean\":\"Average Air Pressure\"}, inplace=True)\n",
    "\n",
    "#Taking air pressure averages across sensor locations\n",
    "data_ap = data_ap.groupby([\"State Code\", \"County Code\", \"Date Local\"])[\"Average Air Pressure\"].mean().reset_index()\n",
    "\n",
    "#_______________________________________________________\n",
    "#Loading in daily Temperature data for years 2014 - 2018\n",
    "\n",
    "data_t = pd.read_csv(\"data/daily_TEMP_2014.csv\")\n",
    "\n",
    "for i in range(2015, 2019):\n",
    "    data_t = pd.concat([data_t, pd.read_csv(\"data/daily_TEMP_\" + str(i) + \".zip\")])\n",
    "    \n",
    "data_t = data_t[[\"State Name\", \"County Name\", \"Date Local\", \"Arithmetic Mean\"]]\n",
    "data_t.rename(columns={\"Arithmetic Mean\":\"Average Temperature\"}, inplace=True)\n",
    "\n",
    "#Taking temperature averages across distinct sensor locations\n",
    "data_t = data_t.groupby([\"State Name\", \"County Name\", \"Date Local\"])[\"Average Temperature\"].mean().reset_index()\n",
    "\n",
    "\n",
    "#_______________________________________________________________\n",
    "#Loading in daily humidity/dew point data for years 2014 - 2018\n",
    "\n",
    "data_h = pd.read_csv(\"data/daily_RH_DP_2014.csv\")\n",
    "\n",
    "for i in range(2015, 2019):\n",
    "    data_h = pd.concat([data_h, pd.read_csv(\"data/daily_RH_DP_\" + str(i) + \".zip\")])\n",
    "\n",
    "data_h = data_h[[\"State Code\", \"County Code\", \"Date Local\", \"Arithmetic Mean\"]]\n",
    "data_h.rename(columns={\"Arithmetic Mean\":\"Average Humidity\"}, inplace=True)\n",
    "\n",
    "#Taking humidity averages across distinct sensor locations\n",
    "data_h = data_h.groupby([\"State Code\", \"County Code\", \"Date Local\"])[\"Average Humidity\"].mean().reset_index()\n",
    "\n",
    "    \n",
    "#_______________________________________________________________\n",
    "#Loading in daily windspeed point data for years 2014 - 2018\n",
    "data_w = pd.read_csv(\"data/daily_WIND_2014.csv\")\n",
    "\n",
    "for i in range(2015, 2019):\n",
    "    data_w = pd.concat([data_w, pd.read_csv(\"data/daily_WIND_\" + str(i) + \".zip\")])\n",
    "    \n",
    "data_w = data_w[[\"State Code\", \"County Code\", \"Date Local\", \"Arithmetic Mean\"]]\n",
    "data_w.rename(columns={\"Arithmetic Mean\":\"Average Windspeed\"}, inplace=True)\n",
    "\n",
    "#Taking Windspeed averages across distinct sensor locations\n",
    "data_w = data_w.groupby([\"State Code\", \"County Code\", \"Date Local\"])[\"Average Windspeed\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>State Code</th>\n",
       "      <th>County Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>AQI</th>\n",
       "      <th>Category</th>\n",
       "      <th>Defining Parameter</th>\n",
       "      <th>Defining Site</th>\n",
       "      <th>Number of Sites Reporting</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>baldwin</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>33</td>\n",
       "      <td>Good</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>01-003-0010</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alabama</td>\n",
       "      <td>baldwin</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>29</td>\n",
       "      <td>Good</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>01-003-0010</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alabama</td>\n",
       "      <td>baldwin</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>29</td>\n",
       "      <td>Good</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>01-003-0010</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alabama</td>\n",
       "      <td>baldwin</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-11</td>\n",
       "      <td>15</td>\n",
       "      <td>Good</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>01-003-0010</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alabama</td>\n",
       "      <td>baldwin</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>22</td>\n",
       "      <td>Good</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>01-003-0010</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State   County  State Code  County Code       Date  AQI Category  \\\n",
       "0  alabama  baldwin           1            3 2014-01-02   33     Good   \n",
       "1  alabama  baldwin           1            3 2014-01-05   29     Good   \n",
       "2  alabama  baldwin           1            3 2014-01-08   29     Good   \n",
       "3  alabama  baldwin           1            3 2014-01-11   15     Good   \n",
       "4  alabama  baldwin           1            3 2014-01-14   22     Good   \n",
       "\n",
       "  Defining Parameter Defining Site  Number of Sites Reporting  Year  Month  \\\n",
       "0              PM2.5   01-003-0010                          1  2014      1   \n",
       "1              PM2.5   01-003-0010                          1  2014      1   \n",
       "2              PM2.5   01-003-0010                          1  2014      1   \n",
       "3              PM2.5   01-003-0010                          1  2014      1   \n",
       "4              PM2.5   01-003-0010                          1  2014      1   \n",
       "\n",
       "   Day  \n",
       "0    2  \n",
       "1    5  \n",
       "2    8  \n",
       "3   11  \n",
       "4   14  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rename({'State Name':'State', 'county Name': 'County'}, axis=1, inplace=True)\n",
    "data['State'] = data['State'].str.lower()\n",
    "data['County'] = data['County'].str.lower()\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Year'] = pd.DatetimeIndex(data['Date']).year\n",
    "data['Month'] = pd.DatetimeIndex(data['Date']).month\n",
    "data['Day'] = pd.DatetimeIndex(data['Date']).day\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Average Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>jefferson</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>37.601300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alabama</td>\n",
       "      <td>jefferson</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>46.520285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alabama</td>\n",
       "      <td>jefferson</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>53.247984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alabama</td>\n",
       "      <td>jefferson</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>63.699870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alabama</td>\n",
       "      <td>jefferson</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>72.347177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State     County  Year  Month  Average Temperature\n",
       "0  alabama  jefferson  2014      1            37.601300\n",
       "1  alabama  jefferson  2014      2            46.520285\n",
       "2  alabama  jefferson  2014      3            53.247984\n",
       "3  alabama  jefferson  2014      4            63.699870\n",
       "4  alabama  jefferson  2014      5            72.347177"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t.rename({'State Name':'State', 'County Name': 'County'}, axis=1, inplace=True)\n",
    "data_t['State'] = data_t['State'].str.lower()\n",
    "data_t['County'] = data_t['County'].str.lower()\n",
    "data_t['Date Local'] = pd.to_datetime(data_t['Date Local'])\n",
    "data_t['Year'] = pd.DatetimeIndex(data_t['Date Local']).year\n",
    "data_t['Month'] = pd.DatetimeIndex(data_t['Date Local']).month\n",
    "data_t['Day'] = pd.DatetimeIndex(data_t['Date Local']).day\n",
    "data_t.head()\n",
    "\n",
    "data_t = data_t.groupby(['State', 'County','Year','Month'])['Average Temperature'].mean().reset_index()\n",
    "data_t.head()\n",
    "#data_w = data_w.groupby([\"State Code\", \"County Code\", \"Date Local\"])[\"Average Windspeed\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t.to_csv(\"./cleaned_data/temps.csv\", index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\" SELECT State, County, MAX(AQI) as max_aqi, MIN(AQI) as min_aqi, AVG(AQI) as avg_aqi, Year, Month\n",
    "            FROM data\n",
    "            GROUP BY State, County, Year, Month\n",
    "\"\"\"\n",
    "data_agg = ps.sqldf(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49500\n"
     ]
    }
   ],
   "source": [
    "data_agg.head()\n",
    "print(len(data_agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg.to_csv(\"./cleaned_data/aqi.csv\", index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./cleaned_data/aqi.csv\", index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Checking Number of Counties for each State\n",
    "query = \"\"\"SELECT 'State Code', COUNT('County Code') from data_t GROUP BY 'State Code'\"\"\"\n",
    "ps.sqldf(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging AQI data with daily weather data\n",
    "data = pd.merge(data, data_t, how=\"left\", left_on=[\"State Code\", \"County Code\", \"Date\"], right_on=[\"State Code\", \"County Code\", \"Date Local\"])\n",
    "data = pd.merge(data, data_ap, how=\"left\", left_on=[\"State Code\", \"County Code\", \"Date\"], right_on=[\"State Code\", \"County Code\", \"Date Local\"])\n",
    "data = pd.merge(data, data_h, how=\"left\", left_on=[\"State Code\", \"County Code\", \"Date\"], right_on=[\"State Code\", \"County Code\", \"Date Local\"])\n",
    "data = pd.merge(data, data_w, how=\"left\", left_on=[\"State Code\", \"County Code\", \"Date\"], right_on=[\"State Code\", \"County Code\", \"Date Local\"])\n",
    "\n",
    "#Extracting year and month from date\n",
    "data[\"Year\"] = data[\"Date\"].apply(lambda x: parser.parse(x).year)\n",
    "data[\"Month\"] = data[\"Date\"].apply(lambda x: parser.parse(x).month)\n",
    "\n",
    "#Renaming Columns\n",
    "data.rename(columns = {\"State Name\":\"State\", \"county Name\":\"County\"}, inplace=True)\n",
    "\n",
    "#Removing trailing blanks from county and state variables\n",
    "data[\"State\"] = data[\"State\"].apply(str.strip)\n",
    "data[\"County\"] = data[\"County\"].apply(str.strip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(state_abbrev, county, year, month, day):\n",
    "    date1 = str(year) + str(month).zfill(2) + str(day).zfill(2)\n",
    "    date2 = str(year) + str(month).zfill(2) + str(day).zfill(2)\n",
    "    url = \"http://api.mesowest.net/v2/stations/statistics?state=\" + state_abbrev + \"&county=\" + county + \"&start=\" + date1 + \"0000&end=\" + date2 + \"0000&vars=air_temp&obtimezone=local&token=demotoken&type=average\"\n",
    "    response = requests.get(url)\n",
    "    return json.loads(response.content.decode(\"latin1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_weather(\"NC\", \"wake\", 2013, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================DATA CHECKS====================\n",
    "#===================================================\n",
    "\n",
    "def check_unique_keys(data_str, *argv):\n",
    "    \"\"\"Checking Number of records for each combination of key variables\n",
    "    There should be only one record per combination, so if there are other \n",
    "    numbers these will have to be looked into\"\"\"\n",
    "    \n",
    "    #Combining all the variables into query argument\n",
    "    varlist = \"\"\n",
    "    for arg in argv:\n",
    "        varlist += (arg + \", \")\n",
    "    \n",
    "    #Removing trailing comma from variable list\n",
    "    varlist = varlist[:-2]\n",
    "    \n",
    "    #Forming full query\n",
    "    query=\"SELECT DISTINCT Count FROM (SELECT \" + varlist + \", COUNT(*) AS Count FROM \" + data_str + \" GROUP BY \" + varlist + \")\"\n",
    "    print(query)\n",
    "    \n",
    "    #Executing query\n",
    "    return(ps.sqldf(query=query))\n",
    "\n",
    "def check_unique_county_map(data_str):\n",
    "    \"\"\"Checking uniqueness of mapping from statenum/countynum to state and county\"\"\"\n",
    "    \n",
    "    #Forming Full query\n",
    "    query = \"SELECT DISTINCT Count FROM (SELECT StateNum, CountyNum, COUNT(*) AS COUNT FROM (SELECT DISTINCT StateNum, CountyNum, State, County FROM \" + data_str + \") GROUP BY StateNum, CountyNum)\"\n",
    "    \n",
    "    #Executing query\n",
    "    return(ps.sqldf(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[\"Average Windspeed\"],data[\"AQI\"]);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
