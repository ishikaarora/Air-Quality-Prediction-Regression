---
title: "ISYE-6414 Final Report - Air Quality Index"
author: "Ishika Arora, Ian Jiang, Tess Leggio"
date: "November 30, 2018"
output:
  pdf_document: default
  html_document: default
---

```{r Setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Loading Script, include=FALSE}
library(MASS)
library(faraway)
library(nlme)
library(leaps)
library(Amelia)
library(pls)
library(mgcv)

#Loading data
# setwd("/Users/tessleggio/GoogleDrive/GeorgiaTech/2018-Fall/01-ISYE-6414/6414Project/cleaned_data")
data_raw <- read.csv("data_nomiss_specificAQI_updatedNov25.csv")
#Dropping missing values in response
data_raw <- data_raw[!is.na(data_raw$AQI),]
#Assigning date from year, month, day
data_raw$date <- as.numeric( difftime(ISOdate(data_raw$Year, data_raw$Month, data_raw$Day, 0), ISOdate(2016,1,1,0), units="days"))

#TEMPERATURE DATA
plot(data_raw$Temperature, data_raw$Month)
data_raw[data_raw$Temperature < -30,]

# remove iberville, louisiana since it is unlikely a county in LA actually saw 
#temperatures in the -38 range
remove <- c("iberville")
data1 <- data_raw
data1 <- data1[!(data1$County %in% remove),]

plot(data1$Temperature, data1$Month)
data1[which(data1$Temperature < -15 & data1$Temperature > -20 & data1$Month == 4),]


# remove effingham, illinois, greenup, kentucky, and roane, tennessee since 
#they have the exact same value for every day and is unlikely to have -17.78 
#in the middle of the summer
remove2 <- c("effingham", "greenup")
data2 <- data1[!(data1$County %in% remove2),]

data2[which(data2$Temperature < -15 & data2$Temperature > -20 & data2$Month == 7),]

remove3 <- c("roane")
data3 <- data2[!(data2$County %in% remove3),]

plot(data3$Temperature, data3$Month)

qqnorm(data3$Temperature)
qqline(data3$Temperature)
#probably needs transformation


#AQI_PM2.5
summary(data_raw$AQI_PM2.5)
plot(data_raw$AQI_PM2.5)
#all values within 0-500 range

qqnorm(data_raw$AQI_PM2.5)
qqline(data_raw$AQI_PM2.5)
#probably needs transformation


#AQI_PM10
summary(data_raw$AQI_PM10)
plot(data_raw$AQI_PM10, data_raw$Month)
#not all values within 0-500 range

#remove values which are outside of the AQI range of 0-500 since 
#something is not right with those values
data_raw[which(data_raw$AQI_PM10 > 500),]
remove4 <- c(8912, 13425)
data4 <- data3[-remove4,]
data4[which(data4$AQI_PM10 > 500),]

plot(data4$AQI_PM10, data4$Month)

qqnorm(data4$AQI_PM10)
qqline(data4$AQI_PM10)
#probably needs transformation

#AQI_CO
summary(data_raw$AQI_CO)
plot(data_raw$AQI_CO, data_raw$Month)
#all values within 0-500 range

qqnorm(data_raw$AQI_CO)
qqline(data_raw$AQI_CO)
#probably needs transformation


#AQI_NO2
summary(data_raw$AQI_NO2)
plot(data_raw$AQI_NO2, data_raw$Month)
#all values within 0-500 range

qqnorm(data_raw$AQI_NO2)
qqline(data_raw$AQI_NO2)
#probably needs transformation

#AQI_Ozone
summary(data_raw$AQI_Ozone)
plot(data_raw$AQI_Ozone, data_raw$Month)
#all values within 0-500 range

qqnorm(data_raw$AQI_Ozone)
qqline(data_raw$AQI_Ozone)
#probably needs transformation

#AQI_SO2
summary(data_raw$AQI_SO2)
plot(data_raw$AQI_SO2, data_raw$Month)
#all values within 0-500 range

qqnorm(data_raw$AQI_SO2)
qqline(data_raw$AQI_SO2)

qqnorm(data4$AQI_SO2)
qqline(data4$AQI_SO2)

data4[which(data4$AQI_SO2 == 200),]
#remove hawaii, hawaii since every single recorded day has the same AQI_SO2
remove5 <- c("hawaii")
data5 <- data4[!(data4$County %in% remove5),]

qqnorm(data5$AQI_SO2)
qqline(data5$AQI_SO2)
#probably needs transformation


#TOTAL EMISSIONS
summary(data_raw$Total.Emissions)
plot(data_raw$Total.Emissions, data_raw$Month)

data_raw[which(data_raw$Total.Emissions == max(data_raw$Total.Emissions)),]

#harris county (county which houses Houston) has much more total emissions 
#than the others, but no real reason to believe it's a bad data point

qqnorm(data5$Total.Emissions)
qqline(data5$Total.Emissions)
#probably needs transformation

#TESS FINAL DATA (NOT INCLUDING IAN'S REMOVALS)
data <- data5

data_PM2.5 <- data[!is.na(data$AQI_PM2.5),]
data_PM10 <- data[!is.na(data$AQI_PM10),]
data_CO <- data[!is.na(data$AQI_CO),]
data_NO2 <- data[!is.na(data$AQI_NO2),]
data_ozone <- data[!is.na(data$AQI_Ozone),]
data_SO2 <- data[!is.na(data$AQI_SO2),]

data_PM2.5 <- subset(data_PM2.5, select=-c(AQI))
colnames(data_PM2.5)[colnames(data_PM2.5)=="AQI_PM2.5"] <- "AQI"

data_PM10 <- subset(data_PM10, select=-c(AQI))
colnames(data_PM10)[colnames(data_PM10)=="AQI_PM10"] <- "AQI"

data_CO <- subset(data_CO, select=-c(AQI))
colnames(data_CO)[colnames(data_CO)=="AQI_CO"] <- "AQI"

data_NO2 <- subset(data_NO2, select=-c(AQI))
colnames(data_NO2)[colnames(data_NO2)=="AQI_NO2"] <- "AQI"

data_ozone <- subset(data_ozone, select=-c(AQI))
colnames(data_ozone)[colnames(data_ozone)=="AQI_Ozone"] <- "AQI"

data_SO2 <- subset(data_SO2, select=-c(AQI))
colnames(data_SO2)[colnames(data_SO2)=="AQI_SO2"] <- "AQI"

```

```{r Full Model, include=FALSE}
lmod <- lm(formula = AQI ~ NF3 + Other.GHG + Total.Emissions + HFC + Other.Fluorane + Biogenic.CO2 + Population + CO2 + PFC + HFE + Stationary.Combustion + pp_consumed_MMBtu + Temperature +  Methane + SF6 + Short.Lived.Compounds + Income +  pp_net_gen_MWh, data = data)

#Remove outliers and high leverage points
hatv <- hatvalues(lmod)
data_mod <- data[hatv < 0.2,]

stud <- rstudent(lmod)
data_mod <- data_mod[stud < 10,]
```

```{r NO2 model, include=FALSE}
lmod.NO2 <- lm(formula = AQI ~ NF3 + Other.GHG + Total.Emissions + HFC + Other.Fluorane + Biogenic.CO2 + Population + CO2 + PFC + HFE + Stationary.Combustion + pp_consumed_MMBtu + Temperature +  Methane + SF6 + Short.Lived.Compounds + Income +  pp_net_gen_MWh, data = data_NO2)

#Remove outliers and high leverage points
hatv <- hatvalues(lmod.NO2)
data_mod_NO2 <- data_NO2[hatv < 0.2,]

stud <- rstudent(lmod)
data_mod_NO2 <- data_mod_NO2[stud < 10,]
```

#1 - Problem Statement

Air quality is a factor that is cited as both contributing to and being affected by climate change, and has been shown to have a direct impact on human health. As a factor with such important consequences, our team decided to study factors that impact air quality. For our project, we focus on answering the following question: *How is air quality across the United States related to demographic, emissions, and weather factors?* Specifically, we chose to investigate the impact of factors related to economic output and climate, including temperature, population, per capita income, greenhouse gas emissions, and industrial power consumption and generation. Our response variable is the Air Quality Index (AQI), a measure of local air quality calculated by the Environmental Protection Agency (EPA) based on the concentrations of 6 major classes of ground-level pollutants: ozone, carbon monoxide, nitrogen dioxide, sulfur dioxide, and two measures of particulate matter (PM2.5 and PM10). Upon building initial models of overall AQI, we found that the residuals differed based on the defining parameter (pollutant class) of the AQI.  Thus, we ended up building models for the 6 individual pollutant AQIs in addition to the overall AQI.

The scope of our analysis ultimately included county-level data for all US counties with available AQI data. To limit the size of our dataset to a size manageable within R, we used daily data from 2016, the most recent year with data available for each of the factors included in our analysis.

In the following analysis, we give results for analysis preformed to generate one of the 7 models, the initial model for overall AQI. We used a similar approach to generate each of the models for the individual AQI defining parameters.

#2 - Data Collection

Most of the data we used in our analysis is available from government websites. Data is available for download as CSV files from the following sources: per capita income data from bea.gov, population data from census.gov, powerplant energy consumption and generation data from eia.gov, and AQI data from aqs.epa.gov.

Weather data were significantly more challenging to collect. Daily weather sensor data is available from aqs.epa.gov, however the county data is far less complete than AQI data, so to avoid omitting a large portion of data from analysis, which could introduce bias into the model we instead collected temperature data from api.mesowest.net, an API which allows straight-forward programmatic extraction of data. By setting parameters in the URL, daily temperature and other weather averages can be scraped for any given day, state and county. We exploit this feature by looping through all counties in the AQI data and all days within our date range, sending a "get" request for each iteration. Data is available in JSON format, and includes daily averages for all stations within a given county. Therefore, a global measure of temperature and other weather factors is easily calculated by converting the JSON format into a Python dictionary and averaging across all stations. The speed of the script is highly dependent on local factors and internet speed, but on average it takes about 10 minutes per county for each of the 1053 counties included in our analysis.

#3 - Data Cleaning

Upon collecting data from each of the 6 identified data sources, we were faced with the task of merging the datasets together.  First and foremost, we had to ensure that the datasets merged together well. We had to merge data based on state name, county name, year, month, and date, so it was essential that these fields were in the exact same format across data sources to avoid loss of data.  In particular, we spent much time ensuring that county names were in the proper format.  Since county name is a string field, it was not uncommon to see several different formats (for example, Saint John vs. St. John vs. StJohn).  To avoid having several sparsely populated observations for each county, we wrote python scripts to format each dataset to use the same format and merge the datasets together.

After merging the datasets, we noted that there were several columns that were only sparsely populated, especially within weather data such as wind speed, relative humidity, and precipitation. As these data were sparse, we decided not to use them in our analysis because it may have introduced bias into the model.  As such, we dropped the columns from our dataset. The remaining dataset was large and did not have a large number of missing values, so we decided to omit NAs from analysis rather than imputing missing data.

Next, we checked our merged data to ensure data quality. One of our more effective methods for investigating data quality was to plot individual predictors versus time to easily spot any clear outliers.  Using this method, we were able to quickly spot clear outliers, such as the county Iberville, Louisiana, which reported temperatures of around -38C in the middle of the summer, which is not a reasonable value and did not align with checks on other websites.  These values and few others were thus identified as clear data quality issues and were omitted from analysis.

Finally, our initial dataset across multiple years included more than a million observations and was too large a file to easily work with within R, so our team made the decision to trim our dataset to a more reasonable size of approximately 330,000 observations by including only data from 2016.

#4 - Model Diagnostics

##Checking Constant Variance Assumption

We check for the constancy of variance by examining the relationship of the residuals to the fitted values of the full model. If residuals follow a normal distribution, then their magnitudes would be half-normally distributed. Therefore, in order to mitigate the effects of the skewedness of this distribution, we also take the square root of the magnitudes, and plot it against the corresponding predictions. 

```{r Residuals vs. Fitted, fig.width=6, fig.height=4,fig.align='center', echo=FALSE}
 #Plot residuals against fitted
plot(lmod$fitted.values, sqrt(abs(lmod$residuals)), xlab="Fitted", ylab=expression(sqrt(hat(epsilon))), main="Residuals vs. Fitted")
```

When the square root residuals are fitted on the estimated response, we find a significant p-value, indicating that there is a dependence of the residuals. Therefore, transformation of either the response or factors are needed. For the moment, we leave the response alone, in order to proceed with the diagnostics.

##Checking Normality Assumption

Next, we investigate whether or not the residuals of the model are normal distributed. For this, we visually examine the histogram of residuals to gain intuition around the distribution of residuals (though a histogram alone is not sufficient to make a determination about the normality of residuals), as well as the qq-plot of residual quartiles against the corresponding Gaussian quartiles.

```{r Figures, fig.width=6, fig.height=5,fig.align='center', echo=FALSE}
par(mfrow=c(2, 2))

 #Plot residuals against fitted
plot(lmod$fitted.values, sqrt(abs(lmod$residuals)), xlab="Fitted", ylab=expression(sqrt(hat(epsilon))), main="Residuals vs. Fitted")

#Checking normality with QQ-plot
qqnorm(lmod$residuals, ylab="Residuals", main="QQ Plot of Residuals")
qqline(residuals(lmod))

#Checking normality with histogram of residuals
hist(residuals(lmod), xlab="Residuals", main="Histogram of Residuals")

#Chceking serial correlations
n <- length(lmod$residuals)

plot(tail(lmod$residuals, n - 1) ~ head(lmod$residuals, n - 1), xlab=expression(hat(epsilon)[i]), ylab=expression(hat(epsilon)[i + 1]))

```


As seen in the above figures, the residuals of the model appear to be right-skewed. The non-normality of the residuals are confirmed using a Shapiro-Wilks test. The p-value for this test is highly significant at the 5% level, so we reject the null hypothesis that the errors are normally distributed.  Further investigation into ways to resolve non-normality will be needed.

```{r Shapiro, echo=FALSE}
#Checking normality with Shapiro-Wilks test
shapiro.test(lmod$residuals[1:4999])
```

##Checking for Serial Correlation

Next, we check the serial correlation in the error, to determine if there is any serial dependence of the residuals. This is achieved by regressing each residual on the previous to determine if there is any trend.  The R squared p-values show that this result is significant, and we can conclude that there is marked serial correlation among the residuals which may be caused by a missing covariate. We plot successive pairs of residuals to visualize this serial correlation in the bottom right of the following set of figures.


##Unusual Points

Next, we address unusual points. As a point of clarification, this is to be distinguished from the examination of extreme points in the data cleaning. In the cleaning, we remove spurious results that are likely due to data entry or data collection errors (such as a failed sensor), while the remaining extreme points are assumed to be naturally-occuring. We first examine the leverages. We produce a qqplot of the residual quantiles against half-normal quantiles to investigate high-leverage points.

```{r Large-Leverages, fig.width=5, fig.height=3,fig.align='center', echo=FALSE}
#Obtaining leverages
hatv <- hatvalues(lmod)
  
#Comparing leverages to the halfnormal distribution
halfnorm(hatv, labs=data$County, ylab="Leverages")
```

In order to preserve the stability and representability of the model, we try removing points with extremely large leverage (h > 0.2). As we have a very large dataset, this does not much change the model. Next, in order to identify outliers, we calculate the studentized residuals of each point, and compare them to the Bonferroni-corrected 5% quartile of a t-distribution with n - p - 1 degrees of freedom. Here we investigate potential outliers with studentized residuals greater than the Bonferroni criterion, which represent about 0.3% of our dataset.

```{r Outliers}
#Calculating Studentized Residuals
stud <- rstudent(lmod)
n = nrow(data)
df = lmod$df
bonferroni <- abs(qt(.05/(n*2),df))
length(stud[abs(stud) > bonferroni])/n
```


##Multicollinearity

To check collinearity of the predictors, we first examine the variable inflation factors for each predictor to identify those with a high (>5) VIF.  A VIF that is high indicates that the standard error is much larger than it would be without collinearity.  We identify 7 factors with high VIF values, so it is clear some predictors are collinear.  Using this model with highly collinear predictors leads to unstable models, which leads to drastic changes in the coefficient estimates with even small perturbations to the response.  We produce and investigate the correlation matrix to better understand which predictors are related to one another.  Armed with this understanding, we remove one high-VIF predictor at a time and rerun analysis so as to ensure we are only only removing predictors that provide redundant information to the model. Using this process, we choose to remove the following variables: Short.Lived.Compounds, CO2, Total.Emissions, pp_net_gen_MWh, Other.Fluorane, and Nitrous.Oxide. 

```{r Collinearity, echo=FALSE}
#Calculating VIFs for all variables
VIF <- vif(lmod)
VIF[VIF > 5]

```
```{r, results = "hide"}
#Calculating correlation matrix 
corr <- round(cor(data[,c("AQI", "HFC", "Other.GHG", "SF6", "Stationary.Combustion", 
    "Biogenic.CO2", "HFE", "NF3", "PFC", "Short.Lived.Compounds", "Temperature", 
    "pp_consumed_MMBtu", "CO2", "Income", "Nitrous.Oxide", "Population", "Total.Emissions", 
    "pp_net_gen_MWh", "Methane", "Other.Fluorane")]),2)
```


#5 - Model Selection 
##A) Stepwise selection
We tried running stepwise regression on the model before removing the collinear variables from the model, but the results were not very satisfactory. It removed only two factors out of the 20 predictors. However, when we looked at the pairwise correlation factors (and plots) and the VIFs, several factors seemed to be strongly correlated. This suggested that we had to remove more than just two factors from the model to address multicollinearity.

##B) Backward selection
Because of the complex interaction of the factors, we decided to use backward elimination for removing non-significant factors from the model. We started with 13 predictors in the model and then removed the predictor with highest p-value greater than 0.05. We removed two more factors from the model and finally used the following factors to train our model -  - *other greenhouse gases, hydrofluorocarbons, biogenic CO2, population, perfluorinated chemicals, hexafluorethane, stationary combustion, industrial power consumption, Temperature, sulfur hexafluoride, and per capita income*.

#6 - Transformations
Based on the model diagnostics, specifically the violations of constant error variance and normality, it was clear we needed to modify the initial model.  Several transformations were performed and tested to see if any transformations resulted in a better-fitting model.  Some of these included square root transformations, adding polynomial terms for the predictors, investigating interactions between predictors, using log transformations, and others.  Adding polynomial terms for Temperature improves the model fit.  Most of the other transformations tested only improved model fit marginally while making it more difficult to interpret the model. Ultimately, we used Box Cox to identify the best transformation on the response.  

Box Cox identified a lambda value of 0.56, so for model interpretability we used a square root transformation on the response.  This helped resolve some, but not all of the error assumption violations while improving the R squared value. All predictors remain significant in this model. We have a relatively large dataset, and in this case it is not uncommone for small deviations from non-normality to be detected.  We continue, however, with this model because we have a large sample size and can lean on the central limit theorem. The errors are not exactly normal, so the least squares estimate may not be optimal, though it will remain the best linear unbiased estimate.  Investigations into robust regression methods, which are used especially when errors are not normally distributed, reveal residual standard errors similar to that of the transformed model. 

Upon completing all of these steps, we repeat analysis steps as necessary as we build and update each of the models for the 6 air quality defining parameters.


```{r, fig.width=5.5, fig.height=3,fig.align='center', echo=FALSE}

lmod.select <- lm(formula = (AQI+1) ~ Other.GHG + HFC +  Biogenic.CO2 + Population + PFC + HFE + Stationary.Combustion + pp_consumed_MMBtu + poly(Temperature,2) + SF6 + Income, data = data_mod)
#summary(lmod.select)

bx <- boxcox(lmod.select, plotit=T, lambda=seq(0.5, 0.6, by=0.01))

#Getting best boxcox parameter -- lambda ~ 0.5
lambda <- bx$x[which.max(bx$y)]

lmod.select.T <- lm(formula = (AQI+1)^0.5 ~ Other.GHG + HFC +  Biogenic.CO2 + Population + PFC + HFE + Stationary.Combustion + pp_consumed_MMBtu + poly(Temperature,2) + SF6 + Income, data = data_mod)
sumary(lmod.select.T)
```

```{r echo=FALSE}

rlmod <- rlm(AQI^0.5 ~ Other.GHG + HFC +  Biogenic.CO2 + Population + PFC + HFE + Stationary.Combustion + pp_consumed_MMBtu + poly(Temperature,2) + SF6 + Income,data)
cat('Robust Regression residual standard error:',summary(rlmod)$sigma)
```

```{r GLS, echo=FALSE, include=FALSE}
#the errors were clearly dependent, so we try generalized least squares on the non-collinear factors:
glmod <- gls(AQI^0.5 ~ Other.GHG + HFC +  Biogenic.CO2 + Population + PFC + HFE + Stationary.Combustion + pp_consumed_MMBtu + Temperature + SF6 + Income,weights=varPower(), data=na.omit(data))
#summary(glmod)

#remove Stationary.Combustion
glmod <- gls(AQI^0.5 ~ Other.GHG + HFC +  Biogenic.CO2 + Population + PFC + HFE + pp_consumed_MMBtu + Temperature + SF6 + Income,weights=varPower(), data=na.omit(data))
#summary(glmod)
```



#7 - Final Model
Based on the diagnostics and transformation results (as shown above), we built the final models for each defining parameter by transforming the response as square root. We used the following set of factors to train the model, which were selected based on the results of multicollinearity tests in the diagnostics section and backwards elimination - *nitrogen trifluoride, other greenhouse gases, hydrofluorocarbons, biogenic CO2, population, perfluorinated chemicals, hexafluorethane, stationary combustion, industrial power consumption, Temperature, methane, sulfur hexafluoride, and per capita income*. The R-squared value of the full final model comes out to be 10.7%. All the predictors are highly statistically significant in this model as shown in the model summary below.

```{r Final Full Model}
lmod.T <- lm(formula = AQI ^ 0.5 ~ Other.GHG + HFC +  Biogenic.CO2 + Population + 
               PFC + HFE + Stationary.Combustion + pp_consumed_MMBtu + 
               poly(Temperature,2) + SF6 + Income, data = data_mod)
sumary(lmod.T)
```

 
Similarly, we built the final component models for each defining parameter with response transformation and selected factors. Here we show the results here for the NO2 AQI model, for which the final R-squared value came out to be 27.1%.

```{r Final NO2 Model, echo=FALSE}
lmod.T.NO2 <- lm(formula = AQI ^ 0.5 ~ Other.GHG + HFC +  Biogenic.CO2 + Population + HFE + Stationary.Combustion + pp_consumed_MMBtu + Temperature + Income, data = na.omit(data_mod_NO2))

cat("NO2 Model R-squared: ",round(summary(lmod.T.NO2)$r.squared,2))
```

#8 - Conclusions and Future Research

Through our analysis, we conclude that the factors used in each of our models, primarily *nitrogen trifluoride, other greenhouse gases, hydrofluorocarbons, biogenic CO2, population, perfluorinated chemicals, hexafluorethane, stationary combustion, industrial power consumption, Temperature, methane, sulfur hexafluoride, and per capita income*, are significantly related to the air quality of a given area.  However, despite highly significant predictors, the relatively low R squared values of the models in addition to somewhat heteroscedasticity in model residuals indicate that there are likely important covariates missing or an underlying nonlinear relationship that may be explored in further analysis.

**Additional predictors: **Future research work can include additional predictors in the model, since only up to about 27% of the variation in the response is explained by the current set of predictors. Some additional factors that can be included are -
*more weather factors (wind speed, humidity and precipitation), geographical data like elevation or use city-level data rather than county-level data*. This may help explain more of the variation in the response as well as help address the serial correlation present in the current fit.

**Additional scope: **We can further investigate air quality with more data collected across the globe so that we have more informational dataset. We can also run the analysis over a larger time interval (current analysis is for a year's worth of data). We could not process more than a year of data in R, so we decided to build the model for the smalle dataset.

**Nonlinear models: **Initial investigation into general additive models seem promising, as even the unrefined model produces a higher percentage of deviance explained than our best linear model for total AQI.  Further analysis is required to better understand if there is an underlying nonlinear relationship in predicting air quality index.
```{r, echo=FALSE}
gammod <- gam(AQI ~ s(HFC) +  s(Biogenic.CO2) + s(Population) + s(HFE) + 
                s(Stationary.Combustion) + s(pp_consumed_MMBtu) + 
                s(Temperature) + s(Income), data=data)
cat("GAM % deviance explained: ",summary(gammod)$dev.expl)
```
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

